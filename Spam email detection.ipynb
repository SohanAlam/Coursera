{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nimport pandas as pd\nimport nltk  \nfrom nltk.corpus import stopwords\nimport string"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Subject: naturally irresistible your corporate...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Subject: the stock trading gunslinger  fanny i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Subject: unbelievable new homes made easy  im ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subject: 4 color printing special  request add...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Subject: do not have money , get software cds ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                                text  spam\n0  Subject: naturally irresistible your corporate...     1\n1  Subject: the stock trading gunslinger  fanny i...     1\n2  Subject: unbelievable new homes made easy  im ...     1\n3  Subject: 4 color printing special  request add...     1\n4  Subject: do not have money , get software cds ...     1"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(5728, 2)"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['text', 'spam'], dtype='object')"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.columns"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(5695, 2)\n"
                }
            ],
            "source": "df.drop_duplicates(inplace=True)\nprint(df.shape)\n#checking for duplicates and removing them"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "text    0\nspam    0\ndtype: int64\n"
                }
            ],
            "source": "print(df.isnull().sum())\n#checking missing data for each column"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package stopwords to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n"
                },
                {
                    "data": {
                        "text/plain": "True"
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# downloading the stopwords package\nnltk.download(\"stopwords\")"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0    [Subject, naturally, irresistible, corporate, ...\n1    [Subject, stock, trading, gunslinger, fanny, m...\n2    [Subject, unbelievable, new, homes, made, easy...\n3    [Subject, 4, color, printing, special, request...\n4    [Subject, money, get, software, cds, software,...\nName: text, dtype: object"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "'''Createing a function to clean the text and return the tokens.\nThe cleaning of the text can be done by first removing punctuation and then removing the useless words also known as stop words.'''\n\ndef process(text):\n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n\n    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n    return clean\n# to show the tokenization\ndf['text'].head().apply(process)"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.feature_extraction.text import CountVectorizer\nmessage = CountVectorizer(analyzer=process).fit_transform(df['text'])"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": "#split the data into 80% training and 20% testing\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(message, df['spam'], test_size=0.20, random_state=0)"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(5695, 37229)\n"
                }
            ],
            "source": "# To see the shape of the data\nprint(message.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": "# create and train the Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB().fit(xtrain, ytrain)"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[0 0 0 ... 0 0 0]\n[0 0 0 ... 0 0 0]\n"
                }
            ],
            "source": "print(classifier.predict(xtrain))\nprint(ytrain.values)"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      3457\n           1       0.99      1.00      0.99      1099\n\n    accuracy                           1.00      4556\n   macro avg       0.99      1.00      1.00      4556\nweighted avg       1.00      1.00      1.00      4556\n\n\nConfusion Matrix: \n [[3445   12]\n [   1 1098]]\nAccuracy: \n 0.9971466198419666\n"
                }
            ],
            "source": "# Evaluating the model on the training data set\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\npred = classifier.predict(xtrain)\nprint(classification_report(ytrain, pred))\nprint()\nprint(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\nprint(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[1 0 0 ... 0 0 0]\n[1 0 0 ... 0 0 0]\n"
                }
            ],
            "source": "#print the predictions\nprint(classifier.predict(xtest))\n#print the actual values\nprint(ytest.values)"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       870\n           1       0.97      1.00      0.98       269\n\n    accuracy                           0.99      1139\n   macro avg       0.98      0.99      0.99      1139\nweighted avg       0.99      0.99      0.99      1139\n\n\nConfusion Matrix: \n [[862   8]\n [  1 268]]\nAccuracy: \n 0.9920983318700615\n"
                }
            ],
            "source": "# Evaluating the model on the training data set\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\npred = classifier.predict(xtest)\nprint(classification_report(ytest, pred))\nprint()\nprint(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\nprint(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}